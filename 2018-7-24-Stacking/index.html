<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.8.0"><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>Stacking方法详解 | CHAI' blog</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/normalize/8.0.1/normalize.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//lib.baomitu.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//lib.baomitu.com/jquery/3.4.0/jquery.min.js"></script><link rel="icon" mask sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Stacking方法详解</h1><a id="logo" href="/.">CHAI' blog</a><p class="description"></p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">Stacking方法详解</h1><div class="post-meta">Jul 24, 2018<span> | </span><span class="category"><a href="/categories/Machine-Learning/">Machine Learning</a></span></div><div class="clear"><div class="toc-article" id="toc"><div class="toc-title">文章目录</div><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#线性加权融合方法"><span class="toc-number">1.</span> <span class="toc-text">线性加权融合方法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#传统方法"><span class="toc-number">1.1.</span> <span class="toc-text">传统方法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#融入多项式等特征"><span class="toc-number">1.2.</span> <span class="toc-text">融入多项式等特征</span></a></li></ol></li></ol></div></div><div class="post-content"><p>stacking方法,是Kaggle比赛中尝试较多的方法。stacking背后的基本思路就是，使用一群基分类器(第一层),然后使用另外一个分类器(第二层)来组合前面第一层的预测结果,stacking的目的最直观的理解就是减小泛化误差.在1992年《STACKED GENERALIZATION》一文中还有一句关于Stacking的理解:</p>
<blockquote>
<p>Stacked generalization can be seen as a more sophisticated version of cross-validation, exploiting a strategy more sophisticated than cross-validation’s crude winner-takes-all for combining the individual generalizers. （翻译：Stack泛化可以被看作是一种更复杂的交叉验证版本，它利用了一种比交叉验证更加复杂的策略，它可以将各个泛化器组合在一起。）</p>
</blockquote>
<p>至于stacking为什么有效,引用University of Notre Dame的ensemble的ppt中的两句话:</p>
<blockquote>
<ul>
<li>If a particular base-classifier incorrectly learned a certain region of the feature space, the second tier (meta) classifier may be able to detect this undesired behavior.（翻译：如果特定的基础分类器错误地学习了特征空间的某个区域，则第二层（元）分类器可能能够检测到这种不期望的行为。）</li>
<li>Along with the learned behaviors of other classifiers, it can correct such improper training.（随着其他分类器的学习行为，它可以纠正这种不正确的训练。）</li>
</ul>
</blockquote>
<h2 id="线性加权融合方法"><a href="#线性加权融合方法" class="headerlink" title="线性加权融合方法"></a>线性加权融合方法</h2><h3 id="传统方法"><a href="#传统方法" class="headerlink" title="传统方法"></a>传统方法</h3><p><img src="单层stacking方法.jpg" alt="单层stacking方法"></p>
<p>假设第一层有$M$个模型，记为$c_1, c_2, …, c_M$。假设采用$N$-fold的方法划分训练集$R$和测试集$E$，分别记为$r_1, r_2, …, r_N$和$e_1, e_2, …, e_N$。</p>
<p>对于任意模型$c_i$，使用训练集$R / r_j$，进行训练。训练完成后，对训练集$r_j$进行预测，记为$Pr_{c_i, r_j}$。对于任意$r_j$，模型$c_i$都会得到一个预测结果。将这些预测结果合并起来，可以得到模型$c_i$对训练集的预测，$Pr_{c_i, r_1} \cup Pr_{c_i, r_2} \cup … \cup Pr_{c_i, r_N} = Pr_{c_i}$。对于每一个模型，重复上述的步骤，都可以得到一个对训练集的预测结果，记为$Pr = { Pr_{c_1}, Pr_{c_2}, …, Pr_{c_M} }$。</p>
<p>对于任意模型$c_i$，在上述的训练过程中，会进行$N$次训练。每次训练后，还需要对训练集进行预测，$N$次预测之后的结果求平均，得到模型$c_i$对训练集的预测$Pe_{c_i}$。对于每一个模型，都可以得到一个对测试集的预测结果，记为$Pe = { Pe_{c_1}, Pe_{c_2}, …, Pe_{c_M} }$。</p>
<p>第二层选择一个新的模型（通常会采用LR模型,不过很多非线性的模型例如XGB等等也都在一些比赛中取得了非常好的效果），对$Pr$进行训练，训练后预测$Pe$，即为最后的结果。</p>
<h3 id="融入多项式等特征"><a href="#融入多项式等特征" class="headerlink" title="融入多项式等特征"></a>融入多项式等特征</h3><p>该方法与上面的方法的一个比较大的区别是,在得到$Pr$之后，加入多项式等其他特征.当然其他的组合也都可以进行尝试.具体的说，在得到$Pr = { Pr_{c_1}, Pr_{c_2}, …, Pr_{c_M} }$之后，可以对任意两个特征$Pr_{c_a}, Pr_{c_b}$进行相乘（相除或者其他操作），形成一个新的特征。</p>
</div><div class="tags"><a href="/tags/集成学习/">集成学习</a></div><div class="post-nav"><a class="pre" href="/Regression-Summary/">回归问题总结</a><a class="next" href="/2018-7-13-DL-RCNN/">RCNN原理及mxnet实现</a></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank"><input type="text" name="q" maxlength="20" placeholder="Search"><input type="hidden" name="sitesearch" value="https://chaideblog.github.io"></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Algorithm/">Algorithm</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/BigData/">BigData</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Deep-Learning/">Deep Learning</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Interview/">Interview</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Java/">Java</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Linux/">Linux</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Machine-Learning/">Machine Learning</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Math/">Math</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Python/">Python</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/Probability-theroy/" style="font-size: 15px;">Probability theroy</a> <a href="/tags/Genetic-Algorithm/" style="font-size: 15px;">Genetic Algorithm</a> <a href="/tags/决策树/" style="font-size: 15px;">决策树</a> <a href="/tags/Python语法/" style="font-size: 15px;">Python语法</a> <a href="/tags/VPS/" style="font-size: 15px;">VPS</a> <a href="/tags/Convex-Optimize/" style="font-size: 15px;">Convex Optimize</a> <a href="/tags/Naive-Bayes/" style="font-size: 15px;">Naive Bayes</a> <a href="/tags/Sublime/" style="font-size: 15px;">Sublime</a> <a href="/tags/Random-Forests/" style="font-size: 15px;">Random Forests</a> <a href="/tags/集成学习/" style="font-size: 15px;">集成学习</a> <a href="/tags/Hadoop/" style="font-size: 15px;">Hadoop</a> <a href="/tags/Java/" style="font-size: 15px;">Java</a> <a href="/tags/FFT/" style="font-size: 15px;">FFT</a> <a href="/tags/Apache/" style="font-size: 15px;">Apache</a> <a href="/tags/树莓派/" style="font-size: 15px;">树莓派</a> <a href="/tags/SVM/" style="font-size: 15px;">SVM</a> <a href="/tags/SGD/" style="font-size: 15px;">SGD</a> <a href="/tags/BGD/" style="font-size: 15px;">BGD</a> <a href="/tags/MBGD/" style="font-size: 15px;">MBGD</a> <a href="/tags/SMO/" style="font-size: 15px;">SMO</a> <a href="/tags/标准化/" style="font-size: 15px;">标准化</a> <a href="/tags/回归/" style="font-size: 15px;">回归</a> <a href="/tags/CTR/" style="font-size: 15px;">CTR</a> <a href="/tags/LeetCode/" style="font-size: 15px;">LeetCode</a> <a href="/tags/LightGBM/" style="font-size: 15px;">LightGBM</a> <a href="/tags/RCNN/" style="font-size: 15px;">RCNN</a> <a href="/tags/目标检测/" style="font-size: 15px;">目标检测</a> <a href="/tags/Interview/" style="font-size: 15px;">Interview</a> <a href="/tags/LR/" style="font-size: 15px;">LR</a> <a href="/tags/FM-FFM/" style="font-size: 15px;">FM/FFM</a> <a href="/tags/Recommend-System/" style="font-size: 15px;">Recommend System</a> <a href="/tags/Natural-Language-Processing/" style="font-size: 15px;">Natural Language Processing</a> <a href="/tags/Recommendation/" style="font-size: 15px;">Recommendation</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2019-5-5-Paper-TEM/">基于决策树的可解释嵌入推荐模型：TEM</a></li><li class="post-list-item"><a class="post-list-link" href="/2019-5-4-Transformer/">Transformer理解与Tensorflow代码阅读</a></li><li class="post-list-item"><a class="post-list-link" href="/2019-4-28-Normalization/">深度学习中各种Normalization</a></li><li class="post-list-item"><a class="post-list-link" href="/2019-4-22-recommend-system-1/">《推荐系统实战》读书笔记（一）</a></li><li class="post-list-item"><a class="post-list-link" href="/2019-4-6-toutiao-interview/">字节跳动广告算法团队实习面试经历（Offer）</a></li><li class="post-list-item"><a class="post-list-link" href="/2019-3-13-xiaomi-interview/">小米信息流推荐实习面试经历（Offer）</a></li><li class="post-list-item"><a class="post-list-link" href="/2019-3-8-sohu-interview/">搜狐推荐算法实习面试经历（Offer）</a></li><li class="post-list-item"><a class="post-list-link" href="/2019-2-27-CTR-LR-FM-FFM/">CTR系列（一）：LR、FM/FFM</a></li><li class="post-list-item"><a class="post-list-link" href="/2019-2-21-ms-bing-interview/">微软Bing组算法（Game Over）</a></li><li class="post-list-item"><a class="post-list-link" href="/2019-1-8-PriorityQueue/">【转】Java容器源码分析之PriorityQueue</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="http://www.example1.com/" title="site-name1" target="_blank">site-name1</a><ul></ul><a href="http://www.example2.com/" title="site-name2" target="_blank">site-name2</a><ul></ul><a href="http://www.example3.com/" title="site-name3" target="_blank">site-name3</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2019 <a href="/." rel="nofollow">CHAI' blog.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css"><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>